{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "heavy-trouble",
   "metadata": {},
   "source": [
    "# Training BIGNet1\n",
    "## steps:\n",
    "1. load 8 pickle data from pkl dir, can be created from \"create dataset.ipynb\" or downloaded from [GNN-data.zip](https://drive.google.com/file/d/1FgSsBIPzOgKaXGAYXavOU56oW8111gu4/view?usp=sharing)\n",
    "2. train bignet. The trained model can also be downloaded [here](https://drive.google.com/file/d/1pIr0VcdTEiTuR4CmwhmQ4YfnaHrbyEm4/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adjustable-tours",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000\n"
     ]
    }
   ],
   "source": [
    "import util as u\n",
    "pkl_folder=\"pkl\"\n",
    "\n",
    "train_set_name = \"%s/train_data_no_aug.pkl\"%pkl_folder\n",
    "train_curve_label_name=\"%s/train_curve_label_no_aug.pkl\"%pkl_folder\n",
    "train_label_name= \"%s/train_label_no_aug.pkl\"%pkl_folder\n",
    "train_dist_mat_name=\"%s/train_dist_mat_no_aug.pkl\"%pkl_folder\n",
    "\n",
    "test_set_name = \"%s/test_data_no_aug.pkl\"%pkl_folder\n",
    "test_curve_label_name=\"%s/test_curve_label_no_aug.pkl\"%pkl_folder\n",
    "test_label_name= \"%s/test_label_no_aug.pkl\"%pkl_folder\n",
    "test_dist_mat_name=\"%s/test_dist_mat_no_aug.pkl\"%pkl_folder\n",
    "\n",
    "train_set, train_curve_label, train_label, train_dist_mat,\\\n",
    "test_set, test_curve_label, test_label, test_dist_mat=\\\n",
    "u.load_dataset(train_set_name, train_curve_label_name, train_label_name, train_dist_mat_name,\n",
    "             test_set_name, test_curve_label_name, test_label_name, test_dist_mat_name)\n",
    "\n",
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "gorgeous-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no augmentation, firsrt layer is average pool\n",
    "model_path=\"trained_bignet1_naug_norm.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "orange-indian",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss 0.61 val loss 0.71 time: 0m 0s\n",
      "epoch 2 train loss 0.68 val loss 0.7 time: 0m 0s\n",
      "epoch 4 train loss 0.57 val loss 0.69 time: 0m 0s\n",
      "epoch 6 train loss 0.52 val loss 0.67 time: 0m 0s\n",
      "epoch 8 train loss 0.49 val loss 0.66 time: 0m 0s\n",
      "epoch 10 train loss 0.45 val loss 0.63 time: 0m 0s\n",
      "epoch 12 train loss 0.45 val loss 0.6 time: 0m 0s\n",
      "epoch 14 train loss 0.59 val loss 0.54 time: 0m 0s\n",
      "epoch 16 train loss 0.36 val loss 0.49 time: 0m 0s\n",
      "epoch 18 train loss 0.23 val loss 0.44 time: 0m 0s\n",
      "epoch 20 train loss 0.24 val loss 0.38 time: 0m 0s\n",
      "epoch 22 train loss 0.38 val loss 0.33 time: 0m 0s\n",
      "epoch 24 train loss 0.17 val loss 0.29 time: 0m 0s\n",
      "epoch 26 train loss 0.17 val loss 0.16 time: 0m 0s\n",
      "epoch 28 train loss 0.24 val loss 0.1 time: 0m 0s\n",
      "epoch 30 train loss 0.07 val loss 0.09 time: 0m 0s\n",
      "epoch 32 train loss 0.21 val loss 0.07 time: 0m 0s\n",
      "epoch 34 train loss 0.07 val loss 0.06 time: 0m 0s\n",
      "epoch 36 train loss 0.07 val loss 0.06 time: 0m 1s\n",
      "epoch 38 train loss 0.05 val loss 0.09 time: 0m 1s\n",
      "epoch 40 train loss 0.12 val loss 0.05 time: 0m 1s\n",
      "epoch 42 train loss 0.29 val loss 0.03 time: 0m 1s\n",
      "epoch 44 train loss 0.04 val loss 0.03 time: 0m 1s\n",
      "epoch 46 train loss 0.03 val loss 0.04 time: 0m 1s\n",
      "epoch 48 train loss 0.07 val loss 0.04 time: 0m 1s\n",
      "epoch 50 train loss 0.19 val loss 0.03 time: 0m 1s\n",
      "epoch 52 train loss 0.05 val loss 0.03 time: 0m 1s\n",
      "epoch 54 train loss 0.05 val loss 0.02 time: 0m 1s\n",
      "epoch 56 train loss 0.02 val loss 0.02 time: 0m 1s\n",
      "epoch 58 train loss 0.02 val loss 0.01 time: 0m 1s\n",
      "epoch 60 train loss 0.04 val loss 0.01 time: 0m 1s\n",
      "epoch 62 train loss 0.07 val loss 0.01 time: 0m 1s\n",
      "epoch 64 train loss 0.03 val loss 0.01 time: 0m 1s\n",
      "epoch 66 train loss 0.03 val loss 0.01 time: 0m 1s\n",
      "epoch 68 train loss 0.12 val loss 0.01 time: 0m 1s\n",
      "epoch 70 train loss 0.03 val loss 0.01 time: 0m 2s\n",
      "epoch 72 train loss 0.01 val loss 0.01 time: 0m 2s\n",
      "epoch 74 train loss 0.19 val loss 0.02 time: 0m 2s\n",
      "epoch 76 train loss 0.1 val loss 0.01 time: 0m 2s\n",
      "epoch 78 train loss 0.04 val loss 0.01 time: 0m 2s\n",
      "epoch 80 train loss 0.06 val loss 0.01 time: 0m 2s\n",
      "epoch 82 train loss 0.83 val loss 0.01 time: 0m 2s\n",
      "epoch 84 train loss 0.02 val loss 0.01 time: 0m 2s\n",
      "epoch 86 train loss 0.01 val loss 0.01 time: 0m 2s\n",
      "epoch 88 train loss 0.01 val loss 0.01 time: 0m 2s\n",
      "epoch 90 train loss 0.02 val loss 0.01 time: 0m 2s\n",
      "epoch 92 train loss 0.02 val loss 0.01 time: 0m 2s\n",
      "epoch 94 train loss 0.02 val loss 0.0 time: 0m 2s\n",
      "epoch 96 train loss 0.01 val loss 0.0 time: 0m 2s\n",
      "epoch 98 train loss 0.01 val loss 0.0 time: 0m 2s\n",
      "epoch 100 train loss 0.06 val loss 0.0 time: 0m 2s\n",
      "epoch 102 train loss 0.13 val loss 0.0 time: 0m 2s\n",
      "epoch 104 train loss 0.01 val loss 0.0 time: 0m 3s\n",
      "epoch 106 train loss 0.01 val loss 0.0 time: 0m 3s\n",
      "epoch 108 train loss 0.01 val loss 0.0 time: 0m 3s\n",
      "epoch 110 train loss 0.01 val loss 0.0 time: 0m 3s\n",
      "epoch 112 train loss 0.01 val loss 0.0 time: 0m 3s\n",
      "epoch 114 train loss 0.07 val loss 0.0 time: 0m 3s\n",
      "epoch 116 train loss 0.01 val loss 0.0 time: 0m 3s\n",
      "epoch 118 train loss 0.01 val loss 0.0 time: 0m 3s\n",
      "epoch 120 train loss 0.01 val loss 0.0 time: 0m 3s\n",
      "epoch 122 train loss 0.01 val loss 0.01 time: 0m 3s\n",
      "epoch 124 train loss 0.02 val loss 0.01 time: 0m 3s\n",
      "epoch 126 train loss 0.01 val loss 0.01 time: 0m 3s\n",
      "epoch 128 train loss 0.01 val loss 0.01 time: 0m 3s\n",
      "epoch 130 train loss 0.01 val loss 0.01 time: 0m 3s\n",
      "epoch 132 train loss 0.04 val loss 0.01 time: 0m 3s\n",
      "epoch 134 train loss 0.05 val loss 0.0 time: 0m 3s\n",
      "epoch 136 train loss 0.01 val loss 0.0 time: 0m 4s\n",
      "epoch 138 train loss 0.02 val loss 0.0 time: 0m 4s\n",
      "epoch 140 train loss 0.01 val loss 0.0 time: 0m 4s\n",
      "epoch 142 train loss 0.0 val loss 0.0 time: 0m 4s\n",
      "epoch 144 train loss 0.08 val loss 0.0 time: 0m 4s\n",
      "epoch 146 train loss 0.01 val loss 0.0 time: 0m 4s\n",
      "epoch 148 train loss 0.0 val loss 0.0 time: 0m 4s\n",
      "epoch 150 train loss 0.0 val loss 0.0 time: 0m 4s\n",
      "epoch 152 train loss 0.03 val loss 0.0 time: 0m 4s\n",
      "epoch 154 train loss 0.01 val loss 0.0 time: 0m 4s\n",
      "epoch 156 train loss 0.0 val loss 0.0 time: 0m 4s\n",
      "epoch 158 train loss 0.0 val loss 0.0 time: 0m 4s\n",
      "epoch 160 train loss 0.01 val loss 0.0 time: 0m 4s\n",
      "epoch 162 train loss 0.0 val loss 0.0 time: 0m 4s\n",
      "epoch 164 train loss 0.01 val loss 0.0 time: 0m 4s\n",
      "epoch 166 train loss 0.01 val loss 0.0 time: 0m 4s\n",
      "epoch 168 train loss 0.0 val loss 0.0 time: 0m 5s\n",
      "epoch 170 train loss 0.0 val loss 0.0 time: 0m 5s\n",
      "epoch 172 train loss 0.0 val loss 0.0 time: 0m 5s\n",
      "epoch 174 train loss 0.0 val loss 0.0 time: 0m 5s\n",
      "epoch 176 train loss 0.0 val loss 0.0 time: 0m 5s\n",
      "epoch 178 train loss 0.01 val loss 0.0 time: 0m 5s\n",
      "epoch 180 train loss 0.0 val loss 0.0 time: 0m 5s\n",
      "epoch 182 train loss 0.0 val loss 0.0 time: 0m 5s\n",
      "epoch 184 train loss 0.0 val loss 0.0 time: 0m 5s\n",
      "epoch 186 train loss 0.0 val loss 0.0 time: 0m 5s\n",
      "epoch 188 train loss 0.04 val loss 0.0 time: 0m 5s\n",
      "epoch 190 train loss 0.0 val loss 0.0 time: 0m 5s\n",
      "epoch 192 train loss 0.0 val loss 0.0 time: 0m 5s\n",
      "epoch 194 train loss 0.83 val loss 0.0 time: 0m 5s\n",
      "epoch 196 train loss 0.0 val loss 0.0 time: 0m 5s\n",
      "epoch 198 train loss 0.0 val loss 0.0 time: 0m 6s\n",
      "epoch 200 train loss 0.0 val loss 0.0 time: 0m 6s\n",
      "epoch 202 train loss 0.0 val loss 0.0 time: 0m 6s\n",
      "epoch 204 train loss 0.0 val loss 0.0 time: 0m 6s\n",
      "epoch 206 train loss 0.0 val loss 0.0 time: 0m 6s\n",
      "epoch 208 train loss 0.04 val loss 0.0 time: 0m 6s\n",
      "epoch 210 train loss 0.0 val loss 0.0 time: 0m 6s\n",
      "epoch 212 train loss 0.0 val loss 0.0 time: 0m 6s\n",
      "epoch 214 train loss 0.0 val loss 0.0 time: 0m 6s\n",
      "epoch 216 train loss 0.03 val loss 0.0 time: 0m 6s\n",
      "epoch 218 train loss 0.03 val loss 0.0 time: 0m 6s\n",
      "epoch 220 train loss 0.0 val loss 0.0 time: 0m 6s\n",
      "epoch 222 train loss 0.04 val loss 0.0 time: 0m 6s\n",
      "epoch 224 train loss 0.0 val loss 0.0 time: 0m 6s\n",
      "epoch 226 train loss 0.0 val loss 0.0 time: 0m 7s\n",
      "epoch 228 train loss 0.0 val loss 0.0 time: 0m 7s\n",
      "epoch 230 train loss 0.0 val loss 0.0 time: 0m 7s\n",
      "epoch 232 train loss 0.0 val loss 0.0 time: 0m 7s\n",
      "epoch 234 train loss 0.0 val loss 0.0 time: 0m 7s\n",
      "epoch 236 train loss 0.0 val loss 0.0 time: 0m 7s\n",
      "epoch 238 train loss 0.03 val loss 0.0 time: 0m 7s\n",
      "epoch 240 train loss 0.0 val loss 0.0 time: 0m 7s\n",
      "epoch 242 train loss 0.03 val loss 0.0 time: 0m 7s\n",
      "epoch 244 train loss 0.03 val loss 0.0 time: 0m 7s\n",
      "epoch 246 train loss 0.0 val loss 0.0 time: 0m 7s\n",
      "epoch 248 train loss 0.0 val loss 0.0 time: 0m 7s\n",
      "epoch 250 train loss 0.0 val loss 0.0 time: 0m 7s\n",
      "epoch 252 train loss 0.0 val loss 0.0 time: 0m 8s\n",
      "epoch 254 train loss 0.62 val loss 0.0 time: 0m 8s\n",
      "epoch 256 train loss 0.0 val loss 0.0 time: 0m 8s\n",
      "epoch 258 train loss 0.0 val loss 0.0 time: 0m 8s\n",
      "epoch 260 train loss 0.0 val loss 0.0 time: 0m 8s\n",
      "epoch 262 train loss 0.0 val loss 0.0 time: 0m 8s\n",
      "epoch 264 train loss 0.04 val loss 0.0 time: 0m 8s\n",
      "epoch 266 train loss 0.0 val loss 0.0 time: 0m 8s\n",
      "epoch 268 train loss 0.0 val loss 0.0 time: 0m 8s\n",
      "epoch 270 train loss 0.0 val loss 0.0 time: 0m 8s\n",
      "epoch 272 train loss 0.12 val loss 0.0 time: 0m 8s\n",
      "epoch 274 train loss 0.0 val loss 0.0 time: 0m 8s\n",
      "epoch 276 train loss 0.0 val loss 0.0 time: 0m 8s\n",
      "epoch 278 train loss 0.0 val loss 0.0 time: 0m 8s\n",
      "epoch 280 train loss 0.0 val loss 0.0 time: 0m 9s\n",
      "epoch 282 train loss 0.0 val loss 0.0 time: 0m 9s\n",
      "epoch 284 train loss 0.0 val loss 0.0 time: 0m 9s\n",
      "epoch 286 train loss 0.0 val loss 0.0 time: 0m 9s\n",
      "epoch 288 train loss 0.02 val loss 0.0 time: 0m 9s\n",
      "epoch 290 train loss 0.03 val loss 0.0 time: 0m 9s\n",
      "epoch 292 train loss 0.02 val loss 0.0 time: 0m 9s\n",
      "epoch 294 train loss 0.02 val loss 0.0 time: 0m 9s\n",
      "epoch 296 train loss 0.0 val loss 0.0 time: 0m 9s\n",
      "epoch 298 train loss 0.0 val loss 0.0 time: 0m 9s\n",
      "epoch 300 train loss 0.0 val loss 0.0 time: 0m 9s\n",
      "epoch 302 train loss 0.0 val loss 0.0 time: 0m 9s\n",
      "epoch 304 train loss 0.91 val loss 0.0 time: 0m 9s\n",
      "epoch 306 train loss 0.0 val loss 0.0 time: 0m 9s\n",
      "epoch 308 train loss 1.43 val loss 0.0 time: 0m 10s\n",
      "epoch 310 train loss 0.0 val loss 0.0 time: 0m 10s\n",
      "epoch 312 train loss 0.0 val loss 0.0 time: 0m 10s\n",
      "epoch 314 train loss 0.0 val loss 0.0 time: 0m 10s\n",
      "epoch 316 train loss 0.0 val loss 0.0 time: 0m 10s\n",
      "epoch 318 train loss 0.04 val loss 0.0 time: 0m 10s\n",
      "epoch 320 train loss 0.0 val loss 0.0 time: 0m 10s\n",
      "epoch 322 train loss 0.0 val loss 0.0 time: 0m 10s\n",
      "epoch 324 train loss 0.0 val loss 0.0 time: 0m 10s\n",
      "epoch 326 train loss 0.0 val loss 0.0 time: 0m 10s\n",
      "epoch 328 train loss 0.0 val loss 0.0 time: 0m 10s\n",
      "epoch 330 train loss 0.0 val loss 0.0 time: 0m 10s\n",
      "epoch 332 train loss 0.0 val loss 0.0 time: 0m 10s\n",
      "epoch 334 train loss 0.0 val loss 0.0 time: 0m 10s\n",
      "epoch 336 train loss 0.0 val loss 0.0 time: 0m 11s\n",
      "epoch 338 train loss 0.04 val loss 0.0 time: 0m 11s\n",
      "epoch 340 train loss 0.0 val loss 0.0 time: 0m 11s\n",
      "epoch 342 train loss 0.0 val loss 0.0 time: 0m 11s\n",
      "epoch 344 train loss 0.0 val loss 0.0 time: 0m 11s\n",
      "epoch 346 train loss 0.0 val loss 0.0 time: 0m 11s\n",
      "epoch 348 train loss 0.0 val loss 0.0 time: 0m 11s\n",
      "epoch 350 train loss 0.03 val loss 0.0 time: 0m 11s\n",
      "epoch 352 train loss 0.03 val loss 0.0 time: 0m 11s\n",
      "epoch 354 train loss 0.0 val loss 0.0 time: 0m 11s\n",
      "epoch 356 train loss 0.02 val loss 0.0 time: 0m 11s\n",
      "epoch 358 train loss 0.0 val loss 0.0 time: 0m 11s\n",
      "epoch 360 train loss 0.0 val loss 0.0 time: 0m 11s\n",
      "epoch 362 train loss 0.0 val loss 0.0 time: 0m 11s\n",
      "epoch 364 train loss 0.0 val loss 0.0 time: 0m 12s\n",
      "epoch 366 train loss 0.03 val loss 0.0 time: 0m 12s\n",
      "epoch 368 train loss 0.0 val loss 0.0 time: 0m 12s\n",
      "epoch 370 train loss 0.03 val loss 0.0 time: 0m 12s\n",
      "epoch 372 train loss 0.0 val loss 0.0 time: 0m 12s\n",
      "epoch 374 train loss 0.0 val loss 0.0 time: 0m 12s\n",
      "epoch 376 train loss 0.03 val loss 0.0 time: 0m 12s\n",
      "epoch 378 train loss 0.0 val loss 0.0 time: 0m 12s\n",
      "epoch 380 train loss 0.0 val loss 0.0 time: 0m 12s\n",
      "epoch 382 train loss 0.0 val loss 0.0 time: 0m 12s\n",
      "epoch 384 train loss 0.0 val loss 0.0 time: 0m 12s\n",
      "epoch 386 train loss 0.03 val loss 0.0 time: 0m 12s\n",
      "epoch 388 train loss 0.0 val loss 0.0 time: 0m 12s\n",
      "epoch 390 train loss 0.03 val loss 0.0 time: 0m 13s\n",
      "epoch 392 train loss 0.0 val loss 0.0 time: 0m 13s\n",
      "epoch 394 train loss 0.0 val loss 0.0 time: 0m 13s\n",
      "epoch 396 train loss 0.0 val loss 0.0 time: 0m 13s\n",
      "epoch 398 train loss 0.0 val loss 0.0 time: 0m 13s\n",
      "epoch 400 train loss 0.02 val loss 0.0 time: 0m 13s\n",
      "epoch 402 train loss 0.0 val loss 0.0 time: 0m 13s\n",
      "epoch 404 train loss 0.0 val loss 0.0 time: 0m 13s\n",
      "epoch 406 train loss 0.0 val loss 0.0 time: 0m 13s\n",
      "epoch 408 train loss 0.04 val loss 0.0 time: 0m 13s\n",
      "epoch 410 train loss 0.0 val loss 0.0 time: 0m 13s\n",
      "epoch 412 train loss 0.0 val loss 0.0 time: 0m 13s\n",
      "epoch 414 train loss 0.0 val loss 0.0 time: 0m 13s\n",
      "epoch 416 train loss 0.0 val loss 0.0 time: 0m 14s\n",
      "epoch 418 train loss 0.0 val loss 0.0 time: 0m 14s\n",
      "epoch 420 train loss 0.0 val loss 0.0 time: 0m 14s\n",
      "epoch 422 train loss 0.0 val loss 0.0 time: 0m 14s\n",
      "epoch 424 train loss 0.03 val loss 0.0 time: 0m 14s\n",
      "epoch 426 train loss 0.0 val loss 0.0 time: 0m 14s\n",
      "epoch 428 train loss 0.0 val loss 0.0 time: 0m 14s\n",
      "epoch 430 train loss 0.0 val loss 0.0 time: 0m 14s\n",
      "epoch 432 train loss 0.0 val loss 0.0 time: 0m 14s\n",
      "epoch 434 train loss 0.0 val loss 0.0 time: 0m 14s\n",
      "epoch 436 train loss 0.0 val loss 0.0 time: 0m 14s\n",
      "epoch 438 train loss 0.0 val loss 0.0 time: 0m 14s\n",
      "epoch 440 train loss 0.0 val loss 0.0 time: 0m 15s\n",
      "epoch 442 train loss 0.04 val loss 0.0 time: 0m 15s\n",
      "epoch 444 train loss 0.0 val loss 0.0 time: 0m 15s\n",
      "epoch 446 train loss 0.68 val loss 0.0 time: 0m 15s\n",
      "epoch 448 train loss 0.0 val loss 0.0 time: 0m 15s\n",
      "epoch 450 train loss 0.0 val loss 0.0 time: 0m 15s\n",
      "epoch 452 train loss 0.0 val loss 0.0 time: 0m 15s\n",
      "epoch 454 train loss 0.0 val loss 0.0 time: 0m 15s\n",
      "epoch 456 train loss 0.04 val loss 0.0 time: 0m 15s\n",
      "epoch 458 train loss 0.03 val loss 0.0 time: 0m 15s\n",
      "epoch 460 train loss 1.83 val loss 0.0 time: 0m 15s\n",
      "epoch 462 train loss 0.04 val loss 0.0 time: 0m 15s\n",
      "epoch 464 train loss 0.03 val loss 0.0 time: 0m 15s\n",
      "epoch 466 train loss 0.0 val loss 0.0 time: 0m 16s\n",
      "epoch 468 train loss 0.03 val loss 0.0 time: 0m 16s\n",
      "epoch 470 train loss 0.0 val loss 0.0 time: 0m 16s\n",
      "epoch 472 train loss 0.0 val loss 0.0 time: 0m 16s\n",
      "epoch 474 train loss 0.0 val loss 0.0 time: 0m 16s\n",
      "epoch 476 train loss 0.66 val loss 0.0 time: 0m 16s\n",
      "epoch 478 train loss 0.0 val loss 0.0 time: 0m 16s\n",
      "epoch 480 train loss 0.0 val loss 0.0 time: 0m 16s\n",
      "epoch 482 train loss 0.0 val loss 0.0 time: 0m 16s\n",
      "epoch 484 train loss 0.0 val loss 0.0 time: 0m 16s\n",
      "epoch 486 train loss 0.0 val loss 0.0 time: 0m 16s\n",
      "epoch 488 train loss 0.0 val loss 0.0 time: 0m 16s\n",
      "epoch 490 train loss 0.05 val loss 0.0 time: 0m 17s\n",
      "epoch 492 train loss 0.03 val loss 0.0 time: 0m 17s\n",
      "epoch 494 train loss 0.04 val loss 0.0 time: 0m 17s\n",
      "epoch 496 train loss 0.04 val loss 0.0 time: 0m 17s\n",
      "epoch 498 train loss 0.03 val loss 0.0 time: 0m 17s\n",
      "epoch 500 train loss 0.04 val loss 0.0 time: 0m 17s\n",
      "epoch 502 train loss 0.0 val loss 0.0 time: 0m 17s\n",
      "epoch 504 train loss 0.03 val loss 0.0 time: 0m 17s\n",
      "epoch 506 train loss 0.0 val loss 0.0 time: 0m 17s\n",
      "epoch 508 train loss 0.0 val loss 0.0 time: 0m 17s\n",
      "epoch 510 train loss 0.03 val loss 0.0 time: 0m 17s\n",
      "epoch 512 train loss 0.64 val loss 0.0 time: 0m 17s\n",
      "epoch 514 train loss 0.0 val loss 0.0 time: 0m 18s\n",
      "epoch 516 train loss 0.0 val loss 0.0 time: 0m 18s\n",
      "epoch 518 train loss 0.0 val loss 0.0 time: 0m 18s\n",
      "epoch 520 train loss 0.0 val loss 0.0 time: 0m 18s\n",
      "epoch 522 train loss 0.0 val loss 0.0 time: 0m 18s\n",
      "epoch 524 train loss 0.02 val loss 0.0 time: 0m 18s\n",
      "epoch 526 train loss 0.0 val loss 0.0 time: 0m 18s\n",
      "epoch 528 train loss 0.03 val loss 0.0 time: 0m 18s\n",
      "epoch 530 train loss 0.0 val loss 0.0 time: 0m 18s\n",
      "epoch 532 train loss 0.02 val loss 0.0 time: 0m 18s\n",
      "epoch 534 train loss 0.0 val loss 0.0 time: 0m 18s\n",
      "epoch 536 train loss 0.03 val loss 0.0 time: 0m 18s\n",
      "epoch 538 train loss 0.0 val loss 0.0 time: 0m 19s\n",
      "epoch 540 train loss 0.03 val loss 0.0 time: 0m 19s\n",
      "epoch 542 train loss 0.0 val loss 0.0 time: 0m 19s\n",
      "epoch 544 train loss 0.0 val loss 0.0 time: 0m 19s\n",
      "epoch 546 train loss 0.0 val loss 0.0 time: 0m 19s\n",
      "epoch 548 train loss 0.6 val loss 0.0 time: 0m 19s\n",
      "epoch 550 train loss 0.0 val loss 0.0 time: 0m 19s\n",
      "epoch 552 train loss 0.0 val loss 0.0 time: 0m 19s\n",
      "epoch 554 train loss 0.04 val loss 0.0 time: 0m 19s\n",
      "epoch 556 train loss 0.0 val loss 0.0 time: 0m 19s\n",
      "epoch 558 train loss 0.0 val loss 0.0 time: 0m 19s\n",
      "epoch 560 train loss 0.0 val loss 0.0 time: 0m 19s\n",
      "epoch 562 train loss 0.0 val loss 0.0 time: 0m 20s\n",
      "epoch 564 train loss 0.04 val loss 0.0 time: 0m 20s\n",
      "epoch 566 train loss 0.0 val loss 0.0 time: 0m 20s\n",
      "epoch 568 train loss 0.0 val loss 0.0 time: 0m 20s\n",
      "epoch 570 train loss 0.0 val loss 0.0 time: 0m 20s\n",
      "epoch 572 train loss 0.0 val loss 0.0 time: 0m 20s\n",
      "epoch 574 train loss 0.72 val loss 0.0 time: 0m 20s\n",
      "epoch 576 train loss 0.04 val loss 0.0 time: 0m 20s\n",
      "epoch 578 train loss 0.0 val loss 0.0 time: 0m 20s\n",
      "epoch 580 train loss 0.04 val loss 0.0 time: 0m 20s\n",
      "epoch 582 train loss 0.02 val loss 0.0 time: 0m 20s\n",
      "epoch 584 train loss 0.0 val loss 0.0 time: 0m 20s\n",
      "epoch 586 train loss 0.0 val loss 0.0 time: 0m 21s\n",
      "epoch 588 train loss 0.0 val loss 0.0 time: 0m 21s\n",
      "epoch 590 train loss 1.32 val loss 0.0 time: 0m 21s\n",
      "epoch 592 train loss 0.0 val loss 0.0 time: 0m 21s\n",
      "epoch 594 train loss 0.0 val loss 0.0 time: 0m 21s\n",
      "epoch 596 train loss 0.0 val loss 0.0 time: 0m 21s\n",
      "epoch 598 train loss 0.04 val loss 0.0 time: 0m 21s\n",
      "epoch 600 train loss 0.0 val loss 0.0 time: 0m 21s\n",
      "epoch 602 train loss 0.0 val loss 0.0 time: 0m 21s\n",
      "epoch 604 train loss 0.04 val loss 0.0 time: 0m 21s\n",
      "epoch 606 train loss 0.0 val loss 0.0 time: 0m 21s\n",
      "epoch 608 train loss 0.0 val loss 0.0 time: 0m 21s\n",
      "epoch 610 train loss 0.0 val loss 0.0 time: 0m 22s\n",
      "epoch 612 train loss 0.0 val loss 0.0 time: 0m 22s\n",
      "epoch 614 train loss 0.0 val loss 0.0 time: 0m 22s\n",
      "epoch 616 train loss 0.03 val loss 0.0 time: 0m 22s\n",
      "epoch 618 train loss 0.04 val loss 0.0 time: 0m 22s\n",
      "epoch 620 train loss 0.0 val loss 0.0 time: 0m 22s\n",
      "epoch 622 train loss 0.0 val loss 0.0 time: 0m 22s\n",
      "epoch 624 train loss 0.06 val loss 0.0 time: 0m 22s\n",
      "epoch 626 train loss 0.04 val loss 0.0 time: 0m 22s\n",
      "epoch 628 train loss 0.03 val loss 0.0 time: 0m 22s\n",
      "epoch 630 train loss 0.0 val loss 0.0 time: 0m 22s\n",
      "epoch 632 train loss 0.0 val loss 0.0 time: 0m 23s\n",
      "epoch 634 train loss 0.03 val loss 0.0 time: 0m 23s\n",
      "epoch 636 train loss 0.03 val loss 0.0 time: 0m 23s\n",
      "epoch 638 train loss 0.03 val loss 0.0 time: 0m 23s\n",
      "epoch 640 train loss 0.0 val loss 0.0 time: 0m 23s\n",
      "epoch 642 train loss 0.04 val loss 0.0 time: 0m 23s\n",
      "epoch 644 train loss 0.0 val loss 0.0 time: 0m 23s\n",
      "epoch 646 train loss 0.04 val loss 0.0 time: 0m 23s\n",
      "epoch 648 train loss 0.0 val loss 0.0 time: 0m 23s\n",
      "epoch 650 train loss 0.0 val loss 0.0 time: 0m 23s\n",
      "epoch 652 train loss 0.03 val loss 0.0 time: 0m 23s\n",
      "epoch 654 train loss 0.04 val loss 0.0 time: 0m 23s\n",
      "epoch 656 train loss 0.0 val loss 0.0 time: 0m 24s\n",
      "epoch 658 train loss 0.02 val loss 0.0 time: 0m 24s\n",
      "epoch 660 train loss 0.0 val loss 0.0 time: 0m 24s\n",
      "epoch 662 train loss 0.04 val loss 0.0 time: 0m 24s\n",
      "epoch 664 train loss 0.0 val loss 0.0 time: 0m 24s\n",
      "epoch 666 train loss 0.0 val loss 0.0 time: 0m 24s\n",
      "epoch 668 train loss 0.0 val loss 0.0 time: 0m 24s\n",
      "epoch 670 train loss 0.03 val loss 0.0 time: 0m 24s\n",
      "epoch 672 train loss 0.0 val loss 0.0 time: 0m 24s\n",
      "epoch 674 train loss 0.0 val loss 0.0 time: 0m 24s\n",
      "epoch 676 train loss 0.03 val loss 0.0 time: 0m 24s\n",
      "epoch 678 train loss 0.0 val loss 0.0 time: 0m 25s\n",
      "epoch 680 train loss 0.04 val loss 0.0 time: 0m 25s\n",
      "epoch 682 train loss 0.04 val loss 0.0 time: 0m 25s\n",
      "epoch 684 train loss 0.0 val loss 0.0 time: 0m 25s\n",
      "epoch 686 train loss 0.03 val loss 0.0 time: 0m 25s\n",
      "epoch 688 train loss 0.04 val loss 0.0 time: 0m 25s\n",
      "epoch 690 train loss 0.0 val loss 0.0 time: 0m 25s\n",
      "epoch 692 train loss 0.0 val loss 0.0 time: 0m 25s\n",
      "epoch 694 train loss 1.32 val loss 0.0 time: 0m 25s\n",
      "epoch 696 train loss 0.03 val loss 0.0 time: 0m 25s\n",
      "epoch 698 train loss 0.0 val loss 0.0 time: 0m 25s\n",
      "epoch 700 train loss 0.0 val loss 0.0 time: 0m 26s\n",
      "epoch 702 train loss 0.0 val loss 0.0 time: 0m 26s\n",
      "epoch 704 train loss 0.02 val loss 0.0 time: 0m 26s\n",
      "epoch 706 train loss 0.04 val loss 0.0 time: 0m 26s\n",
      "epoch 708 train loss 0.0 val loss 0.0 time: 0m 26s\n",
      "epoch 710 train loss 0.83 val loss 0.0 time: 0m 26s\n",
      "epoch 712 train loss 0.0 val loss 0.0 time: 0m 26s\n",
      "epoch 714 train loss 0.0 val loss 0.0 time: 0m 26s\n",
      "epoch 716 train loss 0.0 val loss 0.0 time: 0m 26s\n",
      "epoch 718 train loss 0.0 val loss 0.0 time: 0m 26s\n",
      "epoch 720 train loss 0.03 val loss 0.0 time: 0m 26s\n",
      "epoch 722 train loss 0.04 val loss 0.0 time: 0m 27s\n",
      "epoch 724 train loss 0.0 val loss 0.0 time: 0m 27s\n",
      "epoch 726 train loss 0.6 val loss 0.0 time: 0m 27s\n",
      "epoch 728 train loss 0.0 val loss 0.0 time: 0m 27s\n",
      "epoch 730 train loss 0.0 val loss 0.0 time: 0m 27s\n",
      "epoch 732 train loss 0.0 val loss 0.0 time: 0m 27s\n",
      "epoch 734 train loss 0.03 val loss 0.0 time: 0m 27s\n",
      "epoch 736 train loss 0.0 val loss 0.0 time: 0m 27s\n",
      "epoch 738 train loss 0.02 val loss 0.0 time: 0m 27s\n",
      "epoch 740 train loss 0.0 val loss 0.0 time: 0m 27s\n",
      "epoch 742 train loss 0.0 val loss 0.0 time: 0m 28s\n",
      "epoch 744 train loss 0.0 val loss 0.0 time: 0m 28s\n",
      "epoch 746 train loss 0.0 val loss 0.0 time: 0m 28s\n",
      "epoch 748 train loss 0.04 val loss 0.0 time: 0m 28s\n",
      "epoch 750 train loss 0.0 val loss 0.0 time: 0m 28s\n",
      "epoch 752 train loss 0.04 val loss 0.0 time: 0m 28s\n",
      "epoch 754 train loss 0.02 val loss 0.0 time: 0m 28s\n",
      "epoch 756 train loss 0.0 val loss 0.0 time: 0m 28s\n",
      "epoch 758 train loss 0.0 val loss 0.0 time: 0m 28s\n",
      "epoch 760 train loss 0.0 val loss 0.0 time: 0m 28s\n",
      "epoch 762 train loss 0.0 val loss 0.0 time: 0m 29s\n",
      "epoch 764 train loss 0.0 val loss 0.0 time: 0m 29s\n",
      "epoch 766 train loss 0.0 val loss 0.0 time: 0m 29s\n",
      "epoch 768 train loss 0.0 val loss 0.0 time: 0m 29s\n",
      "epoch 770 train loss 0.0 val loss 0.0 time: 0m 29s\n",
      "epoch 772 train loss 0.0 val loss 0.0 time: 0m 29s\n",
      "epoch 774 train loss 0.0 val loss 0.0 time: 0m 29s\n",
      "epoch 776 train loss 0.66 val loss 0.0 time: 0m 29s\n",
      "epoch 778 train loss 0.0 val loss 0.0 time: 0m 29s\n",
      "epoch 780 train loss 0.0 val loss 0.0 time: 0m 29s\n",
      "epoch 782 train loss 0.0 val loss 0.0 time: 0m 29s\n",
      "epoch 784 train loss 0.0 val loss 0.0 time: 0m 30s\n",
      "epoch 786 train loss 0.0 val loss 0.0 time: 0m 30s\n",
      "epoch 788 train loss 0.05 val loss 0.0 time: 0m 30s\n",
      "epoch 790 train loss 0.0 val loss 0.0 time: 0m 30s\n",
      "epoch 792 train loss 0.0 val loss 0.0 time: 0m 30s\n",
      "epoch 794 train loss 0.03 val loss 0.0 time: 0m 30s\n",
      "epoch 796 train loss 0.0 val loss 0.0 time: 0m 30s\n",
      "epoch 798 train loss 0.0 val loss 0.0 time: 0m 30s\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "import math\n",
    "from torch.optim.lr_scheduler import LambdaLR, StepLR, MultiStepLR,\\\n",
    "ExponentialLR, ReduceLROnPlateau \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "train_accuracy_path=\"%s/train_accuracy_naug_norm.pkl\"%pkl_folder\n",
    "train_loss_path=\"%s/train_loss_naug_norm.pkl\"%pkl_folder\n",
    "val_accuracy_path=\"%s/val_accuracy_naug_norm.pkl\"%pkl_folder\n",
    "val_loss_path=\"%s/val_loss_naug_norm.pkl\"%pkl_folder\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "train_loss_record=[]\n",
    "train_accuracy_record=[]\n",
    "val_loss_record=[]\n",
    "val_accuracy_record=[]\n",
    "val_min=1e9\n",
    "loss_func=nn.BCELoss()\n",
    "train_loss=0 #initialize\n",
    "\n",
    "batch_size=5 #先假設可以整除\n",
    "num_batches=int(len(train_label)/batch_size)\n",
    "model = u.bignet1(batch_size=batch_size)\n",
    "lr=0.001\n",
    "optim = Adam(model.parameters(), lr=lr)\n",
    "scheduler = StepLR(optim, step_size=10, gamma=0.9)\n",
    "\n",
    "#因為create有按照順序，先打亂再batch\n",
    "train_zip=list(zip(train_set,train_curve_label,train_dist_mat,train_label))\n",
    "random.shuffle(train_zip)\n",
    "train_set,train_curve_label,train_dist_mat,train_label=zip(*train_zip)\n",
    "\n",
    "#first evaluatiom\n",
    "model.eval()\n",
    "#temporarily use test as my val\n",
    "model.batch_size=len(test_label)\n",
    "_, val_pred=model(test_set,test_curve_label,test_dist_mat)\n",
    "\n",
    "val_loss=loss_func(val_pred,torch.FloatTensor(test_label))\n",
    "val_loss_record.append(val_loss.item())\n",
    "val_acc=u.binary_acc(val_pred, torch.FloatTensor(test_label))\n",
    "val_accuracy_record.append(val_acc)\n",
    "# print(\"ok\")\n",
    "for epoch in range(800):\n",
    "    start_i=0\n",
    "    model.train()\n",
    "    model.batch_size=batch_size\n",
    "    for iteration in range(num_batches):\n",
    "        train_batch=train_set[start_i:start_i+batch_size]\n",
    "        train_curve_label_batch=train_curve_label[start_i:start_i+batch_size]\n",
    "        train_dist_batch=train_dist_mat[start_i:start_i+batch_size]\n",
    "        train_label_batch=train_label[start_i:start_i+batch_size]\n",
    "        truth=torch.FloatTensor(train_label_batch)\n",
    "        \n",
    "        _, pred=model(train_batch,train_curve_label_batch,train_dist_batch)\n",
    "        train_loss=loss_func(pred,truth)\n",
    "        acc=u.binary_acc(pred, truth)\n",
    "        train_accuracy_record.append(acc)\n",
    "        train_loss_record.append(train_loss.item())\n",
    "        optim.zero_grad()\n",
    "        train_loss.backward(retain_graph=True)\n",
    "        optim.step()\n",
    "        start_i+=batch_size\n",
    "        \n",
    "        u.dump_item(train_accuracy_record, train_accuracy_path)\n",
    "        u.dump_item(train_loss_record, train_loss_path)\n",
    "    \n",
    "    model.eval()\n",
    "    #temporarily use test as my val\n",
    "    model.batch_size=len(test_label)\n",
    "    _, val_pred=model(test_set,test_curve_label,test_dist_mat)\n",
    "    val_loss=loss_func(val_pred,torch.FloatTensor(test_label))\n",
    "    val_loss_record.append(val_loss.item())\n",
    "    val_acc=u.binary_acc(val_pred, torch.FloatTensor(test_label))\n",
    "    val_accuracy_record.append(val_acc)\n",
    "    \n",
    "    u.dump_item(val_accuracy_record, val_accuracy_path)\n",
    "    u.dump_item(val_loss_record, val_loss_path)\n",
    "    \n",
    "    if len(val_loss_record)>10:\n",
    "        if val_loss<val_min:\n",
    "            #save the model\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            val_min=val_loss\n",
    "   \n",
    "    if epoch%2==0:\n",
    "        #shuffle train set to get different batches, but maybe not every time\n",
    "        train_zip=list(zip(train_set,train_curve_label,train_dist_mat,train_label))\n",
    "        random.shuffle(train_zip)\n",
    "        train_set,train_curve_label,train_dist_mat,train_label=zip(*train_zip)\n",
    "        print(\"epoch\",epoch,\"train loss\",round(train_loss.item(),2),\\\n",
    "              \"val loss\",round(val_loss.item(),2),\"time:\",\\\n",
    "              u.timeSince(start))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_accuracy_path=\"%s/train_accuracy_naug_avg.pkl\"%pkl_folder\n",
    "# train_loss_path=\"%s/train_loss_naug_avg.pkl\"%pkl_folder\n",
    "# val_accuracy_path=\"%s/val_accuracy_naug_avg.pkl\"%pkl_folder\n",
    "# val_loss_path=\"%s/val_loss_naug_avg.pkl\"%pkl_folder\n",
    "# u.dump_item(train_accuracy_record, train_accuracy_path)\n",
    "# u.dump_item(train_loss_record, train_loss_path)\n",
    "# u.dump_item(val_accuracy_record, val_accuracy_path)\n",
    "# u.dump_item(val_loss_record, val_loss_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "quick-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plot_epochs=500\n",
    "train_rec_end=plot_epochs * num_batches\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(train_accuracy_record[:train_rec_end],label=\"train\")\n",
    "x_axis = [*range(0, num_batches*(1+plot_epochs), num_batches)]\n",
    "# plt.plot(x_axis, val_accuracy_record)\n",
    "plt.plot(x_axis, val_accuracy_record[:plot_epochs+1],label=\"test\")\n",
    "plt.title(\"accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(train_loss_record[:train_rec_end],label=\"train\")\n",
    "plt.plot(x_axis, val_loss_record[:plot_epochs+1],label=\"test\")\n",
    "plt.title(\"loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel_20210124",
   "language": "python",
   "name": "kernel_20210124"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
